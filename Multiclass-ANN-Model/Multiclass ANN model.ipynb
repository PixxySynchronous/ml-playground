{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a3mH6tJAEN",
   "metadata": {
    "id": "23a3mH6tJAEN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eDQBfLxJAHD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4eDQBfLxJAHD",
    "outputId": "f53cdd54-5368-43f0-e24e-72d6162ef18a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>huml</th>\n",
       "      <th>humw</th>\n",
       "      <th>ulnal</th>\n",
       "      <th>ulnaw</th>\n",
       "      <th>feml</th>\n",
       "      <th>femw</th>\n",
       "      <th>tibl</th>\n",
       "      <th>tibw</th>\n",
       "      <th>tarl</th>\n",
       "      <th>tarw</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>80.78</td>\n",
       "      <td>6.68</td>\n",
       "      <td>72.01</td>\n",
       "      <td>4.88</td>\n",
       "      <td>41.81</td>\n",
       "      <td>3.70</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4.03</td>\n",
       "      <td>38.70</td>\n",
       "      <td>3.84</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>88.91</td>\n",
       "      <td>6.63</td>\n",
       "      <td>80.53</td>\n",
       "      <td>5.59</td>\n",
       "      <td>47.04</td>\n",
       "      <td>4.30</td>\n",
       "      <td>80.22</td>\n",
       "      <td>4.51</td>\n",
       "      <td>41.50</td>\n",
       "      <td>4.01</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>79.97</td>\n",
       "      <td>6.37</td>\n",
       "      <td>69.26</td>\n",
       "      <td>5.28</td>\n",
       "      <td>43.07</td>\n",
       "      <td>3.90</td>\n",
       "      <td>75.35</td>\n",
       "      <td>4.04</td>\n",
       "      <td>38.31</td>\n",
       "      <td>3.34</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>77.65</td>\n",
       "      <td>5.70</td>\n",
       "      <td>65.76</td>\n",
       "      <td>4.77</td>\n",
       "      <td>40.04</td>\n",
       "      <td>3.52</td>\n",
       "      <td>69.17</td>\n",
       "      <td>3.40</td>\n",
       "      <td>35.78</td>\n",
       "      <td>3.41</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>62.80</td>\n",
       "      <td>4.84</td>\n",
       "      <td>52.09</td>\n",
       "      <td>3.73</td>\n",
       "      <td>33.95</td>\n",
       "      <td>2.72</td>\n",
       "      <td>56.27</td>\n",
       "      <td>2.96</td>\n",
       "      <td>31.88</td>\n",
       "      <td>3.13</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   huml  humw  ulnal  ulnaw   feml  femw   tibl  tibw   tarl  tarw type\n",
       "0   0  80.78  6.68  72.01   4.88  41.81  3.70   5.50  4.03  38.70  3.84   SW\n",
       "1   1  88.91  6.63  80.53   5.59  47.04  4.30  80.22  4.51  41.50  4.01   SW\n",
       "2   2  79.97  6.37  69.26   5.28  43.07  3.90  75.35  4.04  38.31  3.34   SW\n",
       "3   3  77.65  5.70  65.76   4.77  40.04  3.52  69.17  3.40  35.78  3.41   SW\n",
       "4   4  62.80  4.84  52.09   3.73  33.95  2.72  56.27  2.96  31.88  3.13   SW"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_data = pd.read_csv('dataset.csv')\n",
    "bird_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NXB0ojtKKkhF",
   "metadata": {
    "id": "NXB0ojtKKkhF"
   },
   "source": [
    "We can see id is redundant here ans python indexes automatically so we set id column as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wXLiyWwOKs27",
   "metadata": {
    "id": "wXLiyWwOKs27"
   },
   "outputs": [],
   "source": [
    "bird_data = bird_data.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6N9cvWNhJAJe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6N9cvWNhJAJe",
    "outputId": "1ae051b6-f68e-4af6-ef35-52626a95a117"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 420 entries, 0 to 419\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   huml    419 non-null    float64\n",
      " 1   humw    419 non-null    float64\n",
      " 2   ulnal   417 non-null    float64\n",
      " 3   ulnaw   418 non-null    float64\n",
      " 4   feml    418 non-null    float64\n",
      " 5   femw    419 non-null    float64\n",
      " 6   tibl    418 non-null    float64\n",
      " 7   tibw    419 non-null    float64\n",
      " 8   tarl    419 non-null    float64\n",
      " 9   tarw    419 non-null    float64\n",
      " 10  type    420 non-null    str    \n",
      "dtypes: float64(10), str(1)\n",
      "memory usage: 36.2 KB\n"
     ]
    }
   ],
   "source": [
    "bird_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "Fkfd-60AJAMN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "Fkfd-60AJAMN",
    "outputId": "85747c17-8355-4ad7-d72c-a4ad033124b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "huml     1\n",
       "humw     1\n",
       "ulnal    3\n",
       "ulnaw    2\n",
       "feml     2\n",
       "femw     1\n",
       "tibl     2\n",
       "tibw     1\n",
       "tarl     1\n",
       "tarw     1\n",
       "type     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bmVFDIJ-MPBF",
   "metadata": {
    "id": "bmVFDIJ-MPBF"
   },
   "source": [
    "To drop null values, we can drop the entire row by dropna function. If large number of values would have been missing then we can also fill the data via several methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "FQ2cAGxIJAOr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "FQ2cAGxIJAOr",
    "outputId": "5ec62a70-c5bf-4ad7-eaf9-665672e94cbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "huml     0\n",
       "humw     0\n",
       "ulnal    0\n",
       "ulnaw    0\n",
       "feml     0\n",
       "femw     0\n",
       "tibl     0\n",
       "tibw     0\n",
       "tarl     0\n",
       "tarw     0\n",
       "type     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_data.dropna (how='any', inplace=True)\n",
    "bird_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7AWNnkbjNFMx",
   "metadata": {
    "id": "7AWNnkbjNFMx"
   },
   "source": [
    "We can find unique values via .nunique() which retruns number of unique values in each column. To get number of classes we can use .unique() on the tyoe column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "xYNw0dmAJARK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYNw0dmAJARK",
    "outputId": "675dbdc2-ef40-46cd-eeec-8e7214624e5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "['SW', 'W', 'T', 'R', 'P', 'SO']\n",
       "Length: 6, dtype: str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_data['type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fURh0ADSNtTJ",
   "metadata": {
    "id": "fURh0ADSNtTJ"
   },
   "source": [
    "The classes above are in string,  but we need digits as model dont understand the word. Or any feature having a non numerical value needs to be changed into numbers and that is done by label encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "Si42n7abJAUS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Si42n7abJAUS",
    "outputId": "e70f215f-5672-4cf3-e664-a34cd1fc6fc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 4, 1, 0, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "bird_data['type'] = le.fit_transform(bird_data['type'])\n",
    "bird_data['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wCu0L0FcJAWo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCu0L0FcJAWo",
    "outputId": "003d4380-e13a-4b81-9b0b-bcc65d605732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(413, 10)\n"
     ]
    }
   ],
   "source": [
    "x = bird_data.drop(['type'], axis = 1 )\n",
    "y = bird_data['type']\n",
    "\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xxEYDA2oQrrz",
   "metadata": {
    "id": "xxEYDA2oQrrz"
   },
   "source": [
    "Now we use one hot encoding on y meaning for example if in row 1 type 3 was present then an array will rep 0,0,0,1,0,0 to tell that type 3 was present for that row. We do this to make a loss function later on ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m9y31zHlQrNE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9y31zHlQrNE",
    "outputId": "07038b2b-29f1-4875-947d-fb91a57a6ac7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "num_classes = 6\n",
    "y = to_categorical(y, num_classes)\n",
    "y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ygRPrOq1PDW9",
   "metadata": {
    "id": "ygRPrOq1PDW9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "U4M5JQiKJAZP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4M5JQiKJAZP",
    "outputId": "9fd6126d-751e-436a-f484-4ad0901906e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(330, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x_cQIxQNUU0L",
   "metadata": {
    "id": "x_cQIxQNUU0L"
   },
   "source": [
    "Why fit() is used ONLY on Training Data\n",
    "1. To Prevent Data Leakage\n",
    "\n",
    "Test data must be completely unseen\n",
    "\n",
    "Using fit() on test data leaks information\n",
    "\n",
    "Leads to unrealistic accuracy\n",
    "\n",
    "2. To Maintain Consistent Scaling\n",
    "\n",
    "Model learns weights based on training scale\n",
    "\n",
    "Test data must use SAME scale\n",
    "\n",
    "Different scaling = wrong predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7mhwKvPLUhWt",
   "metadata": {
    "id": "7mhwKvPLUhWt"
   },
   "source": [
    "While building an ANN model, each layer contains a set of neurons. The Sequential model is used because we are creating the network layer by layer in a linear manner. Dense layers are used to make the network fully connected, where every neuron in one layer is connected to every neuron in the next layer.\n",
    "\n",
    "An ANN generally has three main parts: input layer, hidden layer(s), and output layer. The input layer receives the input data. The input dimension is equal to the number of features in the dataset, which is 10 in this case. The number of units represents the number of neurons in that layer and can be chosen based on the problem.\n",
    "\n",
    "The kernel initializer is used to initialize the weights of the network. It helps start the training process by giving initial values to the weights. The 'uniform' initializer is simple and commonly used, although other initializers like He and Glorot are often better for deep networks.\n",
    "\n",
    "Activation functions are used to introduce non-linearity into the network. ReLU (Rectified Linear Unit) is the most commonly used activation function in hidden layers because it helps the model learn complex patterns and reduces vanishing gradient problems.\n",
    "\n",
    "The model can have two or more hidden layers. Generally, the number of units may increase in deeper layers because early layers learn simple features, while later layers learn more complex and abstract features.\n",
    "\n",
    "In the output layer, the number of units is always equal to the number of classes. The activation function is either sigmoid or softmax because they produce probability values. Sigmoid is used for binary classification, and softmax is used for multi-class classification. These functions do not directly give a class label; instead, they output the probability of the input belonging to each class.\n",
    "\n",
    "The input dimension is specified only in the first (input) layer. After that, Keras automatically infers the dimensions for all subsequent layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UG96Mba5WUa1",
   "metadata": {
    "id": "UG96Mba5WUa1"
   },
   "source": [
    "While fitting (training) the ANN model, we must specify the optimizer, loss function, and metrics. At the output, the model’s prediction is compared with the actual target values to calculate the loss, which represents how far the predicted output is from the true output. For multi-class classification, categorical cross-entropy is commonly used as the loss function.\n",
    "\n",
    "After calculating the loss, the model updates the weights associated with each neuron to reduce this loss. This is done using gradients computed through backpropagation and the previous weights. The optimizer is responsible for calculating the new weights using these gradients. Common optimizers include Gradient Descent and Adam, where Adam is widely used because it adapts the learning rate automatically.\n",
    "\n",
    "The metrics parameter specifies how the model’s performance is evaluated, such as accuracy, which shows how many predictions are correct.\n",
    "\n",
    "The model is then trained using the training data by calling the fit function. During training, the batch size determines how many samples are processed before updating the weights, and epochs represent how many times the entire training dataset is passed through the network. More epochs allow the model to learn better patterns, but too many epochs can cause overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "QfLiaq0cUWyu",
   "metadata": {
    "id": "QfLiaq0cUWyu"
   },
   "outputs": [],
   "source": [
    "from keras.models  import Sequential\n",
    "from keras.layers  import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "OuF8KiQ8UW2P",
   "metadata": {
    "id": "OuF8KiQ8UW2P"
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense (units = 8, kernel_initializer= 'uniform', activation = 'relu', input_dim =10))\n",
    "classifier.add(Dense (units = 16, kernel_initializer= 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense (units = 32, kernel_initializer= 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense (units = 6, kernel_initializer= 'uniform', activation = 'softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "HuMtNMO1UW5g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HuMtNMO1UW5g",
    "outputId": "57f4fc51-f8c7-47d2-be36-2a86b49c670d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2958 - loss: 1.7894\n",
      "Epoch 2/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2830 - loss: 1.7752\n",
      "Epoch 3/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3638 - loss: 1.7471\n",
      "Epoch 4/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5040 - loss: 1.6709\n",
      "Epoch 5/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4601 - loss: 1.5543\n",
      "Epoch 6/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4911 - loss: 1.4828\n",
      "Epoch 7/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4675 - loss: 1.4673\n",
      "Epoch 8/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5170 - loss: 1.3247\n",
      "Epoch 9/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4937 - loss: 1.3132\n",
      "Epoch 10/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4921 - loss: 1.3116\n",
      "Epoch 11/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5214 - loss: 1.2395  \n",
      "Epoch 12/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5075 - loss: 1.2573 \n",
      "Epoch 13/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5602 - loss: 1.1386 \n",
      "Epoch 14/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5491 - loss: 1.1401 \n",
      "Epoch 15/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5338 - loss: 1.1624 \n",
      "Epoch 16/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5144 - loss: 1.1732 \n",
      "Epoch 17/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5119 - loss: 1.1525 \n",
      "Epoch 18/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6122 - loss: 1.0414\n",
      "Epoch 19/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5440 - loss: 1.1572 \n",
      "Epoch 20/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6090 - loss: 1.0256 \n",
      "Epoch 21/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5897 - loss: 1.1048 \n",
      "Epoch 22/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6028 - loss: 1.0530 \n",
      "Epoch 23/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6302 - loss: 0.9620 \n",
      "Epoch 24/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6428 - loss: 0.9134 \n",
      "Epoch 25/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6183 - loss: 0.9629 \n",
      "Epoch 26/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6154 - loss: 0.9689 \n",
      "Epoch 27/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6493 - loss: 0.8914 \n",
      "Epoch 28/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6361 - loss: 0.9510 \n",
      "Epoch 29/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6531 - loss: 0.9013 \n",
      "Epoch 30/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6190 - loss: 0.9623 \n",
      "Epoch 31/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6633 - loss: 0.8332 \n",
      "Epoch 32/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6438 - loss: 0.8972 \n",
      "Epoch 33/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6830 - loss: 0.8282 \n",
      "Epoch 34/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6828 - loss: 0.7954 \n",
      "Epoch 35/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6990 - loss: 0.7556 \n",
      "Epoch 36/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6567 - loss: 0.8381 \n",
      "Epoch 37/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6829 - loss: 0.7750 \n",
      "Epoch 38/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6891 - loss: 0.7725 \n",
      "Epoch 39/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6953 - loss: 0.7636 \n",
      "Epoch 40/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6981 - loss: 0.7510\n",
      "Epoch 41/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6940 - loss: 0.7357 \n",
      "Epoch 42/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7142 - loss: 0.7508 \n",
      "Epoch 43/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7056 - loss: 0.7971 \n",
      "Epoch 44/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6918 - loss: 0.7727 \n",
      "Epoch 45/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7196 - loss: 0.7061 \n",
      "Epoch 46/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7152 - loss: 0.7201 \n",
      "Epoch 47/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6988 - loss: 0.7220 \n",
      "Epoch 48/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7396 - loss: 0.7012 \n",
      "Epoch 49/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7243 - loss: 0.7428 \n",
      "Epoch 50/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7315 - loss: 0.7685 \n",
      "Epoch 51/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7365 - loss: 0.6547 \n",
      "Epoch 52/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7291 - loss: 0.7276 \n",
      "Epoch 53/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7312 - loss: 0.6565 \n",
      "Epoch 54/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.6955 \n",
      "Epoch 55/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7372 - loss: 0.7044 \n",
      "Epoch 56/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6422 \n",
      "Epoch 57/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7583 - loss: 0.6543 \n",
      "Epoch 58/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7142 - loss: 0.7074 \n",
      "Epoch 59/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7381 - loss: 0.6787 \n",
      "Epoch 60/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7577 - loss: 0.6065 \n",
      "Epoch 61/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6907 - loss: 0.7933 \n",
      "Epoch 62/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6972 - loss: 0.7295 \n",
      "Epoch 63/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7433 - loss: 0.6845\n",
      "Epoch 64/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.7020 \n",
      "Epoch 65/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7386 - loss: 0.7093 \n",
      "Epoch 66/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7852 - loss: 0.6101 \n",
      "Epoch 67/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7404 - loss: 0.6079 \n",
      "Epoch 68/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8167 - loss: 0.5660 \n",
      "Epoch 69/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7641 - loss: 0.5854 \n",
      "Epoch 70/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7536 - loss: 0.6077 \n",
      "Epoch 71/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7337 - loss: 0.6459 \n",
      "Epoch 72/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7793 - loss: 0.6292 \n",
      "Epoch 73/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7977 - loss: 0.5506 \n",
      "Epoch 74/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7503 - loss: 0.7006 \n",
      "Epoch 75/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7787 - loss: 0.6162 \n",
      "Epoch 76/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7742 - loss: 0.6268 \n",
      "Epoch 77/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7659 - loss: 0.6613 \n",
      "Epoch 78/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7660 - loss: 0.6058 \n",
      "Epoch 79/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7543 - loss: 0.6353 \n",
      "Epoch 80/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.5592 \n",
      "Epoch 81/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7718 - loss: 0.6206 \n",
      "Epoch 82/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7906 - loss: 0.5701 \n",
      "Epoch 83/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7897 - loss: 0.5915 \n",
      "Epoch 84/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7679 - loss: 0.5964 \n",
      "Epoch 85/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: 0.5209 \n",
      "Epoch 86/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7421 - loss: 0.6708\n",
      "Epoch 87/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7483 - loss: 0.6464 \n",
      "Epoch 88/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.5388 \n",
      "Epoch 89/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7567 - loss: 0.5982 \n",
      "Epoch 90/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7808 - loss: 0.5720 \n",
      "Epoch 91/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7956 - loss: 0.5862 \n",
      "Epoch 92/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7937 - loss: 0.5814 \n",
      "Epoch 93/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7518 - loss: 0.6069 \n",
      "Epoch 94/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7450 - loss: 0.6494 \n",
      "Epoch 95/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6334 \n",
      "Epoch 96/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7911 - loss: 0.5642 \n",
      "Epoch 97/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7820 - loss: 0.5789 \n",
      "Epoch 98/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7958 - loss: 0.5719 \n",
      "Epoch 99/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8177 - loss: 0.5542 \n",
      "Epoch 100/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7673 - loss: 0.5925 \n",
      "Epoch 101/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.5341 \n",
      "Epoch 102/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7954 - loss: 0.5529 \n",
      "Epoch 103/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8166 - loss: 0.5630 \n",
      "Epoch 104/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: 0.5064 \n",
      "Epoch 105/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8148 - loss: 0.5051 \n",
      "Epoch 106/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8061 - loss: 0.5423 \n",
      "Epoch 107/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7783 - loss: 0.5770 \n",
      "Epoch 108/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7732 - loss: 0.5836\n",
      "Epoch 109/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7903 - loss: 0.5653 \n",
      "Epoch 110/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8103 - loss: 0.5927 \n",
      "Epoch 111/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7909 - loss: 0.5489 \n",
      "Epoch 112/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8076 - loss: 0.5126 \n",
      "Epoch 113/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.4776 \n",
      "Epoch 114/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8110 - loss: 0.5216 \n",
      "Epoch 115/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8335 - loss: 0.5162 \n",
      "Epoch 116/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8421 - loss: 0.5023 \n",
      "Epoch 117/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7850 - loss: 0.5687 \n",
      "Epoch 118/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8079 - loss: 0.5005 \n",
      "Epoch 119/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7772 - loss: 0.5885\n",
      "Epoch 120/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8165 - loss: 0.5141\n",
      "Epoch 121/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8025 - loss: 0.5480\n",
      "Epoch 122/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7978 - loss: 0.5457\n",
      "Epoch 123/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 0.5342\n",
      "Epoch 124/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8076 - loss: 0.5176\n",
      "Epoch 125/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8066 - loss: 0.5118\n",
      "Epoch 126/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8137 - loss: 0.5070\n",
      "Epoch 127/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8142 - loss: 0.4978\n",
      "Epoch 128/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8218 - loss: 0.5033\n",
      "Epoch 129/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8097 - loss: 0.5505\n",
      "Epoch 130/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8291 - loss: 0.4932\n",
      "Epoch 131/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7868 - loss: 0.5435\n",
      "Epoch 132/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8167 - loss: 0.4818  \n",
      "Epoch 133/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.5315 \n",
      "Epoch 134/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7935 - loss: 0.5093 \n",
      "Epoch 135/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7636 - loss: 0.6512 \n",
      "Epoch 136/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8199 - loss: 0.5127 \n",
      "Epoch 137/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7932 - loss: 0.5466 \n",
      "Epoch 138/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8120 - loss: 0.4960 \n",
      "Epoch 139/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.5158 \n",
      "Epoch 140/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8135 - loss: 0.4788 \n",
      "Epoch 141/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8267 - loss: 0.4481 \n",
      "Epoch 142/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8359 - loss: 0.4637\n",
      "Epoch 143/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7993 - loss: 0.5523 \n",
      "Epoch 144/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8115 - loss: 0.5369 \n",
      "Epoch 145/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8328 - loss: 0.4800 \n",
      "Epoch 146/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8544 - loss: 0.4444 \n",
      "Epoch 147/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8211 - loss: 0.4652 \n",
      "Epoch 148/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8226 - loss: 0.5027 \n",
      "Epoch 149/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4532 \n",
      "Epoch 150/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8357 - loss: 0.4809 \n",
      "Epoch 151/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.5173 \n",
      "Epoch 152/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8531 - loss: 0.4415 \n",
      "Epoch 153/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7664 - loss: 0.5796 \n",
      "Epoch 154/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8169 - loss: 0.4939 \n",
      "Epoch 155/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8383 - loss: 0.4948 \n",
      "Epoch 156/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.4754 \n",
      "Epoch 157/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8214 - loss: 0.4880 \n",
      "Epoch 158/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8311 - loss: 0.4377 \n",
      "Epoch 159/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.4726 \n",
      "Epoch 160/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8511 - loss: 0.4634 \n",
      "Epoch 161/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8619 - loss: 0.4455 \n",
      "Epoch 162/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8227 - loss: 0.4766 \n",
      "Epoch 163/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8214 - loss: 0.5351 \n",
      "Epoch 164/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8454 - loss: 0.4597\n",
      "Epoch 165/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8220 - loss: 0.4833 \n",
      "Epoch 166/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8670 - loss: 0.4493 \n",
      "Epoch 167/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8270 - loss: 0.4893 \n",
      "Epoch 168/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8460 - loss: 0.4399 \n",
      "Epoch 169/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8295 - loss: 0.4673 \n",
      "Epoch 170/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8406 - loss: 0.4461 \n",
      "Epoch 171/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8419 - loss: 0.4642 \n",
      "Epoch 172/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8276 - loss: 0.4656 \n",
      "Epoch 173/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8532 - loss: 0.3972 \n",
      "Epoch 174/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8425 - loss: 0.4550 \n",
      "Epoch 175/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8642 - loss: 0.4252\n",
      "Epoch 176/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8762 - loss: 0.3874 \n",
      "Epoch 177/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.4548 \n",
      "Epoch 178/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8593 - loss: 0.4151 \n",
      "Epoch 179/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8357 - loss: 0.4746 \n",
      "Epoch 180/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8565 - loss: 0.4017 \n",
      "Epoch 181/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.5037 \n",
      "Epoch 182/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8616 - loss: 0.4111 \n",
      "Epoch 183/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8528 - loss: 0.4366 \n",
      "Epoch 184/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8772 - loss: 0.3764 \n",
      "Epoch 185/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8507 - loss: 0.4619 \n",
      "Epoch 186/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8292 - loss: 0.4446 \n",
      "Epoch 187/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8355 - loss: 0.4119 \n",
      "Epoch 188/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8441 - loss: 0.4462 \n",
      "Epoch 189/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8956 - loss: 0.4070 \n",
      "Epoch 190/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.4956 \n",
      "Epoch 191/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8675 - loss: 0.3991 \n",
      "Epoch 192/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8744 - loss: 0.3762 \n",
      "Epoch 193/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.4385 \n",
      "Epoch 194/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8573 - loss: 0.4402 \n",
      "Epoch 195/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8665 - loss: 0.4283 \n",
      "Epoch 196/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8853 - loss: 0.4057 \n",
      "Epoch 197/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 0.4245\n",
      "Epoch 198/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8340 - loss: 0.4679 \n",
      "Epoch 199/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8769 - loss: 0.4037 \n",
      "Epoch 200/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.3774 \n",
      "Epoch 201/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8538 - loss: 0.4164 \n",
      "Epoch 202/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3940 \n",
      "Epoch 203/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8570 - loss: 0.3775 \n",
      "Epoch 204/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8322 - loss: 0.4772 \n",
      "Epoch 205/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.3488 \n",
      "Epoch 206/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8336 - loss: 0.4235 \n",
      "Epoch 207/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8316 - loss: 0.4261 \n",
      "Epoch 208/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8473 - loss: 0.4701\n",
      "Epoch 209/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4245 \n",
      "Epoch 210/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8740 - loss: 0.3761 \n",
      "Epoch 211/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8914 - loss: 0.3904 \n",
      "Epoch 212/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8611 - loss: 0.4158 \n",
      "Epoch 213/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8629 - loss: 0.3823 \n",
      "Epoch 214/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8608 - loss: 0.4267 \n",
      "Epoch 215/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8784 - loss: 0.3637 \n",
      "Epoch 216/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8594 - loss: 0.3852 \n",
      "Epoch 217/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8768 - loss: 0.3827 \n",
      "Epoch 218/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8697 - loss: 0.3935 \n",
      "Epoch 219/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8615 - loss: 0.3802 \n",
      "Epoch 220/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8630 - loss: 0.4114 \n",
      "Epoch 221/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8520 - loss: 0.4380 \n",
      "Epoch 222/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8587 - loss: 0.4203 \n",
      "Epoch 223/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8475 - loss: 0.3997 \n",
      "Epoch 224/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8932 - loss: 0.3405 \n",
      "Epoch 225/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8606 - loss: 0.3895 \n",
      "Epoch 226/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8514 - loss: 0.3976 \n",
      "Epoch 227/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8673 - loss: 0.3730 \n",
      "Epoch 228/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8827 - loss: 0.3435 \n",
      "Epoch 229/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8820 - loss: 0.3490 \n",
      "Epoch 230/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8998 - loss: 0.3447 \n",
      "Epoch 231/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8607 - loss: 0.3885 \n",
      "Epoch 232/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8854 - loss: 0.3312 \n",
      "Epoch 233/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8990 - loss: 0.3150 \n",
      "Epoch 234/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8819 - loss: 0.3487 \n",
      "Epoch 235/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8857 - loss: 0.3649 \n",
      "Epoch 236/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8934 - loss: 0.3672 \n",
      "Epoch 237/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8730 - loss: 0.3830 \n",
      "Epoch 238/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9003 - loss: 0.3129\n",
      "Epoch 239/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8604 - loss: 0.3772\n",
      "Epoch 240/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8740 - loss: 0.3612\n",
      "Epoch 241/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8822 - loss: 0.3166\n",
      "Epoch 242/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8861 - loss: 0.3787\n",
      "Epoch 243/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8628 - loss: 0.3862\n",
      "Epoch 244/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8846 - loss: 0.3253\n",
      "Epoch 245/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8657 - loss: 0.4396\n",
      "Epoch 246/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 0.3767\n",
      "Epoch 247/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8950 - loss: 0.3331\n",
      "Epoch 248/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8630 - loss: 0.4252\n",
      "Epoch 249/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8968 - loss: 0.3495\n",
      "Epoch 250/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8950 - loss: 0.3474  \n",
      "Epoch 251/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8432 - loss: 0.2947\n",
      "Epoch 252/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 0.3316 \n",
      "Epoch 253/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8692 - loss: 0.3551 \n",
      "Epoch 254/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.2979 \n",
      "Epoch 255/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8928 - loss: 0.3451 \n",
      "Epoch 256/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8617 - loss: 0.3278 \n",
      "Epoch 257/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8845 - loss: 0.2947 \n",
      "Epoch 258/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8893 - loss: 0.3567 \n",
      "Epoch 259/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.3305 \n",
      "Epoch 260/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8680 - loss: 0.3264 \n",
      "Epoch 261/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8924 - loss: 0.3286 \n",
      "Epoch 262/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8929 - loss: 0.3433\n",
      "Epoch 263/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8886 - loss: 0.3441 \n",
      "Epoch 264/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8559 - loss: 0.4012 \n",
      "Epoch 265/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8617 - loss: 0.4169 \n",
      "Epoch 266/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8684 - loss: 0.3527 \n",
      "Epoch 267/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 0.3227 \n",
      "Epoch 268/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9052 - loss: 0.2532 \n",
      "Epoch 269/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9026 - loss: 0.3069 \n",
      "Epoch 270/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8913 - loss: 0.3314 \n",
      "Epoch 271/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8991 - loss: 0.2947 \n",
      "Epoch 272/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9031 - loss: 0.2935\n",
      "Epoch 273/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8914 - loss: 0.3144 \n",
      "Epoch 274/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9054 - loss: 0.2969 \n",
      "Epoch 275/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.2497 \n",
      "Epoch 276/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.2858 \n",
      "Epoch 277/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8825 - loss: 0.3222 \n",
      "Epoch 278/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9002 - loss: 0.2955 \n",
      "Epoch 279/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8705 - loss: 0.3489 \n",
      "Epoch 280/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9231 - loss: 0.3011 \n",
      "Epoch 281/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8613 - loss: 0.3484 \n",
      "Epoch 282/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8638 - loss: 0.3479 \n",
      "Epoch 283/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9063 - loss: 0.2890 \n",
      "Epoch 284/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9012 - loss: 0.2922 \n",
      "Epoch 285/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8899 - loss: 0.3236 \n",
      "Epoch 286/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.3358 \n",
      "Epoch 287/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8836 - loss: 0.2974 \n",
      "Epoch 288/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9279 - loss: 0.2434 \n",
      "Epoch 289/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9272 - loss: 0.2480 \n",
      "Epoch 290/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8852 - loss: 0.3544 \n",
      "Epoch 291/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.2968 \n",
      "Epoch 292/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9197 - loss: 0.2519 \n",
      "Epoch 293/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9053 - loss: 0.2601 \n",
      "Epoch 294/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8697 - loss: 0.3413 \n",
      "Epoch 295/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9136 - loss: 0.2857 \n",
      "Epoch 296/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8988 - loss: 0.3129 \n",
      "Epoch 297/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8876 - loss: 0.3340 \n",
      "Epoch 298/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.2820 \n",
      "Epoch 299/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9102 - loss: 0.3372 \n",
      "Epoch 300/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.2503 \n",
      "Epoch 301/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.2877 \n",
      "Epoch 302/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8991 - loss: 0.2959 \n",
      "Epoch 303/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9208 - loss: 0.2756 \n",
      "Epoch 304/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9207 - loss: 0.2947 \n",
      "Epoch 305/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2805 \n",
      "Epoch 306/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9029 - loss: 0.3053 \n",
      "Epoch 307/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9100 - loss: 0.2617 \n",
      "Epoch 308/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8942 - loss: 0.2931 \n",
      "Epoch 309/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9287 - loss: 0.2731 \n",
      "Epoch 310/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9323 - loss: 0.2511 \n",
      "Epoch 311/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.2190 \n",
      "Epoch 312/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.3365 \n",
      "Epoch 313/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9043 - loss: 0.3062 \n",
      "Epoch 314/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9042 - loss: 0.2638 \n",
      "Epoch 315/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9020 - loss: 0.2685 \n",
      "Epoch 316/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.2785 \n",
      "Epoch 317/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9323 - loss: 0.2416 \n",
      "Epoch 318/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 0.2746 \n",
      "Epoch 319/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9083 - loss: 0.2682 \n",
      "Epoch 320/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9068 - loss: 0.2854 \n",
      "Epoch 321/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.2632 \n",
      "Epoch 322/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9221 - loss: 0.2325 \n",
      "Epoch 323/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9094 - loss: 0.3025 \n",
      "Epoch 324/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9184 - loss: 0.2667 \n",
      "Epoch 325/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.2217 \n",
      "Epoch 326/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9186 - loss: 0.2860\n",
      "Epoch 327/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9007 - loss: 0.2713 \n",
      "Epoch 328/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9207 - loss: 0.2407 \n",
      "Epoch 329/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2911 \n",
      "Epoch 330/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9103 - loss: 0.2388 \n",
      "Epoch 331/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.2785 \n",
      "Epoch 332/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2657 \n",
      "Epoch 333/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9323 - loss: 0.2146 \n",
      "Epoch 334/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.2183 \n",
      "Epoch 335/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.2500 \n",
      "Epoch 336/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9191 - loss: 0.2447 \n",
      "Epoch 337/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2640 \n",
      "Epoch 338/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.2112 \n",
      "Epoch 339/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9257 - loss: 0.2760 \n",
      "Epoch 340/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9112 - loss: 0.2750 \n",
      "Epoch 341/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 0.2416 \n",
      "Epoch 342/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9104 - loss: 0.2696 \n",
      "Epoch 343/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.3160 \n",
      "Epoch 344/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.2774 \n",
      "Epoch 345/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8813 - loss: 0.2922 \n",
      "Epoch 346/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 0.2606 \n",
      "Epoch 347/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8929 - loss: 0.3065 \n",
      "Epoch 348/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.2485 \n",
      "Epoch 349/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9089 - loss: 0.2690 \n",
      "Epoch 350/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2309 \n",
      "Epoch 351/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9302 - loss: 0.2307 \n",
      "Epoch 352/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9264 - loss: 0.2564\n",
      "Epoch 353/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8950 - loss: 0.2639\n",
      "Epoch 354/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8994 - loss: 0.2509\n",
      "Epoch 355/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9352 - loss: 0.2316\n",
      "Epoch 356/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9061 - loss: 0.2436\n",
      "Epoch 357/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9053 - loss: 0.2612\n",
      "Epoch 358/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9222 - loss: 0.2339\n",
      "Epoch 359/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8980 - loss: 0.3077\n",
      "Epoch 360/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9151 - loss: 0.3012\n",
      "Epoch 361/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9091 - loss: 0.2575\n",
      "Epoch 362/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9261 - loss: 0.2365  \n",
      "Epoch 363/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.3191 \n",
      "Epoch 364/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8755 - loss: 0.3243 \n",
      "Epoch 365/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9057 - loss: 0.2882 \n",
      "Epoch 366/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9313 - loss: 0.2191 \n",
      "Epoch 367/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.2506 \n",
      "Epoch 368/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.2400 \n",
      "Epoch 369/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.2710 \n",
      "Epoch 370/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.2636 \n",
      "Epoch 371/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2643 \n",
      "Epoch 372/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8964 - loss: 0.3106 \n",
      "Epoch 373/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.2203 \n",
      "Epoch 374/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9304 - loss: 0.2345 \n",
      "Epoch 375/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9256 - loss: 0.2099 \n",
      "Epoch 376/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2545 \n",
      "Epoch 377/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9199 - loss: 0.2571\n",
      "Epoch 378/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9321 - loss: 0.2141 \n",
      "Epoch 379/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.2251 \n",
      "Epoch 380/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2596 \n",
      "Epoch 381/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9238 - loss: 0.2423 \n",
      "Epoch 382/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9304 - loss: 0.2120 \n",
      "Epoch 383/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9234 - loss: 0.2238 \n",
      "Epoch 384/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9279 - loss: 0.2259 \n",
      "Epoch 385/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9072 - loss: 0.2240 \n",
      "Epoch 386/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9249 - loss: 0.2007 \n",
      "Epoch 387/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.1931 \n",
      "Epoch 388/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9153 - loss: 0.2799 \n",
      "Epoch 389/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.2041 \n",
      "Epoch 390/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9030 - loss: 0.2622 \n",
      "Epoch 391/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9236 - loss: 0.2401 \n",
      "Epoch 392/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9297 - loss: 0.2256 \n",
      "Epoch 393/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9231 - loss: 0.2669 \n",
      "Epoch 394/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.1986 \n",
      "Epoch 395/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.2624 \n",
      "Epoch 396/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9460 - loss: 0.2138 \n",
      "Epoch 397/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.2464 \n",
      "Epoch 398/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.2350 \n",
      "Epoch 399/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9217 - loss: 0.2401 \n",
      "Epoch 400/400\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9308 - loss: 0.2196 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7e28082f6150>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.fit(x_train, y_train, batch_size = 16, epochs = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "oyH2osMmUW71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyH2osMmUW71",
    "outputId": "c2ca117d-d067-4b9c-a44e-ef1b514a5701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9138 - loss: 0.2468\n",
      "Train score: 0.23546969890594482\n",
      "Train accuracy: 0.918181836605072\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 2.4779  \n",
      "Test score: 1.3914625644683838\n",
      "Test accuracy: 0.8072289228439331\n"
     ]
    }
   ],
   "source": [
    "score,acc = classifier.evaluate(x_train, y_train, batch_size=10)\n",
    "print('Train score:', score)\n",
    "print('Train accuracy:', acc)\n",
    "\n",
    "score , acc = classifier.evaluate(x_test, y_test, batch_size=10)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "Da5EiXC4UW-c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Da5EiXC4UW-c",
    "outputId": "9df2958f-ecd1-435b-f626-efd7a4cf4286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[3 3 0 3 5 2 1 3 3 3 3 2 5 3 2 2 3 3 2 5 3 2 0 5 2 0 4 1 0 5 1 2 3 2 3 3 3\n",
      " 2 2 2 0 2 3 1 2 2 5 3 0 2 4 1 2 2 5 2 5 0 1 0 1 1 3 5 1 3 3 2 0 4 5 3 1 3\n",
      " 2 1 5 5 2 3 1 2 5]\n",
      "[3 3 2 1 5 2 1 3 3 3 3 2 5 3 2 2 3 3 2 5 3 2 0 5 2 1 4 2 1 5 1 2 3 2 3 3 3\n",
      " 2 2 2 1 2 3 1 2 2 3 5 3 2 4 5 2 2 3 2 5 2 5 0 1 1 5 0 1 3 3 2 0 4 5 3 5 3\n",
      " 2 1 5 5 2 3 1 2 5]\n"
     ]
    }
   ],
   "source": [
    "pred = classifier.predict(x_test)\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print ( y_pred)\n",
    "print ( y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "CjICxXazd57d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjICxXazd57d",
    "outputId": "fc9b9f7c-7eec-47b6-b893-7fd338dbac00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  0  0  0  0  1]\n",
      " [ 3  8  0  1  0  0]\n",
      " [ 2  1 23  0  0  0]\n",
      " [ 1  0  0 20  0  2]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  3  0  2  0 10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "target_names = ['P', 'R', 'SO', 'SW', 'T', 'W']\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aet1rKCseVPz",
   "metadata": {
    "id": "aet1rKCseVPz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "P6KkkGcteayp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "P6KkkGcteayp",
    "outputId": "45a2da4a-9378-4a8b-d0af-906c3a0b696d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(50.722222222222214, 0.5, 'True')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Confusion Matrix')\n",
    "sns.heatmap(cm, cmap='Blues', annot=True, fmt='d', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8tWAO3ooeigv",
   "metadata": {
    "id": "8tWAO3ooeigv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
